import tkinter as tk
from tkinter import ttk
from PIL import Image, ImageTk
import torch
from transformers import CLIPProcessor, CLIPModel
import os
import glob

# --- ì„¤ì • ---
MODEL_NAME = "openai/clip-vit-large-patch14"
IMAGE_DIR = "assets"  # ì´ë¯¸ì§€ê°€ ì €ì¥ëœ í´ë” ì´ë¦„
IMAGE_EXTENSIONS = ["*.jpg", "*.jpeg", "*.png", "*.bmp"] # ê²€ìƒ‰í•  ì´ë¯¸ì§€ í™•ì¥ì
TOP_N_RESULTS = 6  # ìƒìœ„ ëª‡ ê°œì˜ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤„ì§€

# --- GPU ì„¤ì • ---
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"ğŸš€ ì‚¬ìš©í•˜ëŠ” ì¥ì¹˜: {device.upper()}")

# --- ëª¨ë¸ ë° í”„ë¡œì„¸ì„œ ë¡œë“œ ---
print("ğŸ¤– CLIP ëª¨ë¸ê³¼ í”„ë¡œì„¸ì„œë¥¼ ë¡œë“œí•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤...")
model = CLIPModel.from_pretrained(MODEL_NAME).to(device)
processor = CLIPProcessor.from_pretrained(MODEL_NAME)
print("âœ… ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ!")

# --- ì´ë¯¸ì§€ ì‚¬ì „ ì²˜ë¦¬ ---
image_paths = []
for ext in IMAGE_EXTENSIONS:
    image_paths.extend(glob.glob(os.path.join(IMAGE_DIR, ext)))

image_embeddings = []
if image_paths:
    print(f"ğŸ–¼ï¸ ì´ {len(image_paths)}ê°œì˜ ì´ë¯¸ì§€ë¥¼ ì‚¬ì „ ì²˜ë¦¬í•©ë‹ˆë‹¤. ì ì‹œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...")
    with torch.no_grad():
        for path in image_paths:
            try:
                image = Image.open(path).convert("RGB")
                inputs = processor(images=image, return_tensors="pt").to(device)
                embedding = model.get_image_features(**inputs)
                image_embeddings.append(embedding)
            except Exception as e:
                print(f"ê²½ê³ : '{path}' íŒŒì¼ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ - {e}")
    
    # ì„ë² ë”©ë“¤ì„ í•˜ë‚˜ì˜ í…ì„œë¡œ ê²°í•©
    image_embeddings = torch.cat(image_embeddings)
    # ì •ê·œí™” (ìœ ì‚¬ë„ ê³„ì‚° ì„±ëŠ¥ í–¥ìƒ)
    image_embeddings /= image_embeddings.norm(p=2, dim=-1, keepdim=True)
    print("âœ… ì´ë¯¸ì§€ ì‚¬ì „ ì²˜ë¦¬ ì™„ë£Œ!")
else:
    print(f"ê²½ê³ : '{IMAGE_DIR}' í´ë”ì—ì„œ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    exit()

# --- GUI ì• í”Œë¦¬ì¼€ì´ì…˜ ---
class ImageSearchApp:
    def __init__(self, root):
        self.root = root
        self.root.title("CLIP ì´ë¯¸ì§€ ê²€ìƒ‰ê¸°")
        self.root.geometry("800x600")

        # ê²€ìƒ‰ í”„ë ˆì„
        search_frame = ttk.Frame(root, padding="10")
        search_frame.pack(fill=tk.X)

        ttk.Label(search_frame, text="ê²€ìƒ‰ì–´ ì…ë ¥:").pack(side=tk.LEFT, padx=5)
        self.search_entry = ttk.Entry(search_frame, width=50)
        self.search_entry.pack(side=tk.LEFT, fill=tk.X, expand=True, padx=5)
        self.search_entry.bind("<Return>", self.search_images) # ì—”í„° í‚¤ë¡œ ê²€ìƒ‰

        self.search_button = ttk.Button(search_frame, text="ğŸ” ê²€ìƒ‰", command=self.search_images)
        self.search_button.pack(side=tk.LEFT, padx=5)

        # ê²°ê³¼ í”„ë ˆì„
        self.result_frame = ttk.Frame(root, padding="10")
        self.result_frame.pack(fill=tk.BOTH, expand=True)

    def search_images(self, event=None):
        query = self.search_entry.get()
        if not query:
            return

        print(f"\nğŸ” ê²€ìƒ‰ì–´ '{query}'ë¡œ ê²€ìƒ‰ì„ ì‹œì‘í•©ë‹ˆë‹¤...")

        # ì´ì „ ê²°ê³¼ ì‚­ì œ
        for widget in self.result_frame.winfo_children():
            widget.destroy()

        # í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±
        with torch.no_grad():
            text_inputs = processor(text=query, return_tensors="pt").to(device)
            text_embedding = model.get_text_features(**text_inputs)
            text_embedding /= text_embedding.norm(p=2, dim=-1, keepdim=True)

        # ìœ ì‚¬ë„ ê³„ì‚° (ì½”ì‚¬ì¸ ìœ ì‚¬ë„)
        similarities = (text_embedding @ image_embeddings.T).squeeze(0)
        
        # ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬
        top_indices = similarities.argsort(descending=True)[:TOP_N_RESULTS]

        print(f"âœ¨ ìƒìœ„ {len(top_indices)}ê°œ ê²°ê³¼:")
        # ê²°ê³¼ ì´ë¯¸ì§€ í‘œì‹œ
        for i, idx in enumerate(top_indices):
            path = image_paths[idx]
            score = similarities[idx].item()
            print(f"  - {i+1}ìœ„: {path} (ìœ ì‚¬ë„: {score:.4f})")

            img = Image.open(path)
            img.thumbnail((200, 200)) # ì¸ë„¤ì¼ í¬ê¸° ì¡°ì ˆ
            photo = ImageTk.PhotoImage(img)

            item_frame = ttk.Frame(self.result_frame)
            img_label = ttk.Label(item_frame, image=photo)
            img_label.image = photo
            img_label.pack()
            
            score_label = ttk.Label(item_frame, text=f"ìœ ì‚¬ë„: {score:.3f}")
            score_label.pack()

            item_frame.grid(row=i//3, column=i%3, padx=10, pady=10)
    
if __name__ == "__main__":
    root = tk.Tk()
    app = ImageSearchApp(root)
    root.mainloop()